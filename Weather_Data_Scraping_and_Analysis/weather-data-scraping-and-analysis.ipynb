{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8091530,"sourceType":"datasetVersion","datasetId":4777213}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Folder Placements</h1>\n<ul>\n  <li><strong>Weather_Data_Scraping_and_Analysis</strong>\n    <ul>\n      <li><strong>weather.csv:</strong> Contains the main weather data with columns including city, latitude, and longitude.</li>\n      <li><strong>Dataset:</strong> Folder containing CSV files with weather data for different cities.</li>\n        <ul>\n          <li>[Contains CSV files with weather data for different cities]</li>\n        </ul>\n      <li><strong>cities_not_scraped.csv:</strong> CSV file containing the list of cities from weather.csv that were not scraped successfully.</li>\n      <li><strong>Weather_Data_Scraping_and_Analysis.ipynb:</strong> Jupyter notebook file for data scraping and analysis.</li>\n    </ul>\n  </li>\n</ul>\n","metadata":{}},{"cell_type":"markdown","source":"<h1>Import Libraries</h1>\n<ul>\n  <li><strong>csv:</strong> To read and write CSV files.</li>\n  <li><strong>os:</strong> To interact with the operating system, e.g., file paths.</li>\n  <li><strong>time:</strong> To introduce delays.</li>\n  <li><strong>requests_cache:</strong> For caching HTTP requests.</li>\n  <li><strong>retry:</strong> For retrying failed operations.</li>\n  <li><strong>pandas:</strong> For data manipulation and analysis.</li>\n  <li><strong>openmeteo_requests:</strong> Custom library for interacting with the Open-Meteo API.</li>\n  <li><strong>retry_requests:</strong> Library for retrying failed HTTP requests.</li>\n</ul>\n","metadata":{}},{"cell_type":"code","source":"# Cell 1: Import necessary libraries\n!pip install openmeteo_requests\n!pip install retry_requests\n!pip install requests_cache\n\nimport csv\nimport os\nimport time\nimport requests_cache\nfrom retry_requests import retry\nimport pandas as pd\nimport openmeteo_requests\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T17:52:14.683953Z","iopub.execute_input":"2024-04-11T17:52:14.684373Z","iopub.status.idle":"2024-04-11T17:53:01.073938Z","shell.execute_reply.started":"2024-04-11T17:52:14.684339Z","shell.execute_reply":"2024-04-11T17:53:01.072496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cell 2: Rename Duplicates\n<div>\n    <p>This Python script reads a CSV file containing weather data, identifies duplicate city names, and renames them with a numeric suffix to make them unique. It then writes the modified data to a new CSV file. Here's a breakdown of the script:</p>\n    <ol>\n        <li>It defines a function <code>rename_duplicates</code> that takes a CSV file path as input.</li>\n        <li>Inside the function:\n            <ul>\n                <li>It initializes an empty dictionary <code>city_count</code> to store counts of each city.</li>\n                <li>It initializes an empty list <code>new_rows</code> to store modified rows.</li>\n                <li>It opens the input CSV file in read mode.</li>\n                <li>It reads the CSV file using <code>csv.DictReader</code> to treat each row as a dictionary.</li>\n                <li>It iterates over each row in the CSV file.\n                    <ul>\n                        <li>For each row:\n                            <ul>\n                                <li>It retrieves the city name from the 'City' column.</li>\n                                <li>If the city name is already in <code>city_count</code>, it increments the count and renames the city with a numeric suffix.</li>\n                                <li>If the city name is not in <code>city_count</code>, it adds the city to <code>city_count</code> with a count of 0.</li>\n                                <li>It appends the modified row to the <code>new_rows</code> list.</li>\n                            </ul>\n                        </li>\n                    </ul>\n                </li>\n                <li>It closes the input CSV file.</li>\n                <li>It defines the output CSV file path by appending '_modified' to the input file name.</li>\n                <li>It opens the output CSV file in write mode.</li>\n                <li>It writes the modified data to the output CSV file using <code>csv.DictWriter</code>.</li>\n                <li>It closes the output CSV file.</li>\n            </ul>\n        </li>\n    </ol>\n</div>\n","metadata":{}},{"cell_type":"code","source":"import os\n\n# Path to the input directory\ninput_dir = '/kaggle/input/'\n\n# List all files in the input directory\ninput_files = os.listdir(input_dir)\n\n# Print the names of all files\nfor file_name in input_files:\n    print(file_name)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T17:53:01.076196Z","iopub.execute_input":"2024-04-11T17:53:01.076808Z","iopub.status.idle":"2024-04-11T17:53:01.089335Z","shell.execute_reply.started":"2024-04-11T17:53:01.076776Z","shell.execute_reply":"2024-04-11T17:53:01.087876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\n\ndef rename_duplicates(csv_file):\n    \n    # Initialize a dictionary to store city counts\n    city_count = {}\n    new_rows = []\n\n    # Open the CSV file and read its contents\n    with open(csv_file, 'r') as file:\n        reader = csv.DictReader(file)\n        \n        # Iterate through each row in the CSV\n        for row in reader:\n            city = row['City']\n            # Check if the city is already in the dictionary\n            if city in city_count:\n                # If yes, increment the count and rename the city\n                city_count[city] += 1\n                row['City'] = f\"{city}{city_count[city]:02d}\"\n            else:\n                # If no, add the city to the dictionary with count 0\n                city_count[city] = 0\n            \n            # Append the modified row to the new_rows list\n            new_rows.append(row)\n\n    # Write the modified data to a new CSV file\n    new_csv_file = '/kaggle/working/weather_modified.csv'\n    with open(new_csv_file, 'w', newline='') as file:\n        writer = csv.DictWriter(file, fieldnames=new_rows[0].keys())\n        writer.writeheader()\n        writer.writerows(new_rows)\n\n# Call the function to rename duplicates in the weather.csv file\nrename_duplicates(\"/kaggle/input/weather.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T17:53:01.091042Z","iopub.execute_input":"2024-04-11T17:53:01.091514Z","iopub.status.idle":"2024-04-11T17:53:01.165855Z","shell.execute_reply.started":"2024-04-11T17:53:01.091483Z","shell.execute_reply":"2024-04-11T17:53:01.164579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<!-- Cell 3 Markdown -->\n# Cell 3: Data Scraping Setup\n- **Setup**: \n  - Define the number of runs and initialize a dictionary to store scraped cities.\n- **Loop**: \n  - Iterate through each run.\n- **Open-Meteo API Client**:\n  - Setup caching and retry mechanism for API requests.\n- **Read Coordinates**:\n  - Read city coordinates from the \"weather.csv\" file.\n- **Variables**:\n  - Initialize variables to track statistics.\n","metadata":{}},{"cell_type":"code","source":"# Cell 3: Set up variables for data scraping\n\n# Setup the Open-Meteo API client with cache and retry on error\ncache_session = requests_cache.CachedSession('.cache', expire_after=-1)\nretry_session = retry(cache_session, retries=5, backoff_factor=0.2)\nopenmeteo = openmeteo_requests.Client(session=retry_session)\n\n# Read city coordinates from the \"weather.csv\" file\nweather_data_path = '/kaggle/working/weather_modified.csv'\ndf = pd.read_csv(weather_data_path)\n\n# Folder to store downloaded datasets\ndataset_folder = '/kaggle/working/Dataset'\n\n# Variables to keep track of statistics\ntotal_cities = len(df)\ntotal_downloaded = 0\ntotal_remaining = 0\n\n# Dictionary to store successfully downloaded cities\nscraped_cities = {}\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T17:53:01.168405Z","iopub.execute_input":"2024-04-11T17:53:01.168772Z","iopub.status.idle":"2024-04-11T17:53:01.218441Z","shell.execute_reply.started":"2024-04-11T17:53:01.168742Z","shell.execute_reply":"2024-04-11T17:53:01.217163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<!-- Cell 4 Markdown -->\n# Cell 4: Data Scraping\n- **Iterate Through Cities**:\n  - Iterate through each city in the dataset.\n- **API Request**:\n  - Make requests to Open-Meteo API for weather data.\n- **Process Data**:\n  - Process API responses and save data to CSV.\n- **Statistics**:\n  - Print statistics on total cities, downloaded, and remaining.\n","metadata":{}},{"cell_type":"code","source":"import os\nimport time\n\n\n\n# Create the dataset folder if it doesn't exist\ndataset_folder = '/kaggle/working/Dataset'\nif not os.path.exists(dataset_folder):\n    os.makedirs(dataset_folder)\n\n# Define TOTAL_EXISTING\nexisting_files = os.listdir(dataset_folder)\nTOTAL_EXISTING = len([file for file in existing_files if file.endswith('.csv')])\n\n# Number of times to run the loop\nnum_runs = 2\n\n# Loop to run the code multiple times\nfor run in range(1, num_runs + 1):\n    print(f\"\\nRun {run} of {num_runs}:\")\n    # Initialize error counter\n    error_count = 0\n    # Reset total downloaded for each run\n    total_downloaded = 0\n\n    # Iterate through cities\n    for i in range(10):  # assuming you want to iterate through 3 cities\n        City = df.iloc[i]['City']\n        Lat = df.iloc[i]['Lat']\n        Lng = df.iloc[i]['Lng']\n\n        # Check if data for the city already exists\n        file_name = f'{City}.csv'\n        file_path = os.path.join(dataset_folder, file_name)\n        if os.path.exists(file_path):\n            print(f\"Data for {City} already exists. Skipping...\")\n            continue\n\n        # Specify API request parameters\n        url = \"https://archive-api.open-meteo.com/v1/archive\"\n        params = {\n            \"latitude\": Lat,\n            \"longitude\": Lng,\n            \"start_date\": \"2010-01-01\",\n            \"end_date\": \"2024-02-20\",\n            \"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"dew_point_2m\", \"apparent_temperature\", \"precipitation\", \"rain\", \"snowfall\", \"snow_depth\", \"pressure_msl\", \"surface_pressure\", \"cloud_cover\", \"cloud_cover_low\", \"cloud_cover_mid\", \"cloud_cover_high\", \"wind_speed_10m\", \"wind_speed_100m\", \"wind_direction_10m\", \"wind_direction_100m\", \"wind_gusts_10m\"]\n        }\n\n        # Make API request\n        try:\n            responses = openmeteo.weather_api(url, params=params)\n        except Exception as e:\n            print(f\"Error fetching data for {City}: {e}\")\n            error_count += 1  # Increment error count\n            time.sleep(5)  # Delay for 5 second before continuing\n            continue\n\n        # Print city name as it is downloaded\n        print(f\"Downloading data for {City}...\")\n\n        # Process first location. Add a for-loop for multiple locations or weather models\n        response = responses[0]\n\n        # Process hourly data\n        hourly = response.Hourly()\n\n        # Process and save data to CSV\n        hourly_data = {\n            \"date\": pd.date_range(\n                start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n                end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n                freq=pd.Timedelta(seconds=hourly.Interval()),\n                inclusive=\"left\"\n            ),\n            \"temperature_2m\": hourly.Variables(0).ValuesAsNumpy(),\n            \"relative_humidity_2m\": hourly.Variables(1).ValuesAsNumpy(),\n            \"dew_point_2m\": hourly.Variables(2).ValuesAsNumpy(),\n            \"apparent_temperature\": hourly.Variables(3).ValuesAsNumpy(),\n            \"precipitation\": hourly.Variables(4).ValuesAsNumpy(),\n            \"rain\": hourly.Variables(5).ValuesAsNumpy(),\n            \"snowfall\": hourly.Variables(6).ValuesAsNumpy(),\n            \"snow_depth\": hourly.Variables(7).ValuesAsNumpy(),\n            \"pressure_msl\": hourly.Variables(8).ValuesAsNumpy(),\n            \"surface_pressure\": hourly.Variables(9).ValuesAsNumpy(),\n            \"cloud_cover\": hourly.Variables(10).ValuesAsNumpy(),\n            \"cloud_cover_low\": hourly.Variables(11).ValuesAsNumpy(),\n            \"cloud_cover_mid\": hourly.Variables(12).ValuesAsNumpy(),\n            \"cloud_cover_high\": hourly.Variables(13).ValuesAsNumpy(),\n            \"wind_speed_10m\": hourly.Variables(14).ValuesAsNumpy(),\n            \"wind_speed_100m\": hourly.Variables(15).ValuesAsNumpy(),\n            \"wind_direction_10m\": hourly.Variables(16).ValuesAsNumpy(),\n            \"wind_direction_100m\": hourly.Variables(17).ValuesAsNumpy(),\n            \"wind_gusts_10m\": hourly.Variables(18).ValuesAsNumpy(),\n        }\n\n        # Create a DataFrame from the processed data\n        hourly_dataframe = pd.DataFrame(data=hourly_data)\n\n        # Save the DataFrame to CSV with the original city name\n        hourly_dataframe.to_csv(file_path)\n\n        total_downloaded += 1\n\n    # Calculate the total remaining cities to be downloaded\n    total_remaining = total_cities - total_downloaded - TOTAL_EXISTING\n\n    # Print statistics for each run\n    print(f\"\\nTotal Cities: {total_cities}\")\n    print(f\"Total Downloaded for Run {run}: {total_downloaded}\")\n    print(f\"Total Existing: {TOTAL_EXISTING}\")\n    print(f\"Total Remaining: {total_remaining}\")\n    print(f\"Total Errors: {error_count}\")\n\nprint(\"All runs completed.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T17:54:57.323011Z","iopub.execute_input":"2024-04-11T17:54:57.323642Z","iopub.status.idle":"2024-04-11T17:56:12.275777Z","shell.execute_reply.started":"2024-04-11T17:54:57.323609Z","shell.execute_reply":"2024-04-11T17:56:12.274493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cell 5: Display details of the CSV file\n\n```html\n<!-- Displaying information about the CSV file -->\n<p>Dataframe Information:</p>\n{{ df_sample_info }}\n\n<!-- Displaying shape of the CSV file -->\n<p>Dataframe Shape:</p>\n{{ df_sample_shape }}\n\n<!-- Displaying descriptive statistics of the CSV file -->\n<p>Dataframe Descriptive Statistics:</p>\n{{ df_sample_describe }}\n","metadata":{}},{"cell_type":"code","source":"# Cell 5: Import necessary libraries\nimport pandas as pd\nimport os\n\n# Specify the path to the CSV file you want to display\ncsv_file_path = '/kaggle/working/Dataset/Delhi.csv'\n\n# Load the CSV file into a DataFrame\ndf_sample = pd.read_csv(csv_file_path)\n\n# Display the DataFrame\ndf_sample.head()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T17:56:27.956080Z","iopub.execute_input":"2024-04-11T17:56:27.956525Z","iopub.status.idle":"2024-04-11T17:56:28.489816Z","shell.execute_reply.started":"2024-04-11T17:56:27.956492Z","shell.execute_reply":"2024-04-11T17:56:28.488764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Displaying all details about the CSV file\ndf_sample_info = df_sample.info()\ndf_sample_shape = df_sample.shape\ndf_sample_describe = df_sample.describe()\n\ndf_sample_info, df_sample_shape, df_sample_describe","metadata":{"execution":{"iopub.status.busy":"2024-04-11T17:56:30.664378Z","iopub.execute_input":"2024-04-11T17:56:30.664812Z","iopub.status.idle":"2024-04-11T17:56:30.854871Z","shell.execute_reply.started":"2024-04-11T17:56:30.664778Z","shell.execute_reply":"2024-04-11T17:56:30.854083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<!-- Cell 6 Markdown -->\n# Cell 6: Find Cities Not Scraped\n- **Read Weather Data**:\n  - Read the \"weather.csv\" file to get city names.\n- **Extract Unique Cities**:\n  - Extract unique city names along with their coordinates.\n- **Find Missing Cities**:\n  - Compare cities in the weather dataset with those in the dataset folder to find missing cities.\n- **Save Results**:\n  - Save the list of cities not scraped to a CSV file.\n","metadata":{}},{"cell_type":"code","source":"# Cell 6: Find cities not scraped\n# Read the weather.csv file\nweather_csv_path = '/kaggle/working/weather_modified.csv'\ndf_weather = pd.read_csv(weather_csv_path)\n\n# Extract unique city names from weather.csv\nunique_cities_weather = df_weather[['City', 'Lat', 'Lng']].drop_duplicates()\n\n# Directory containing the dataset files\ndataset_folder = '/kaggle/working/Dataset'\n\n# Get list of unique city names from filenames in the dataset folder\nfiles_in_dataset = os.listdir(dataset_folder)\nunique_cities_dataset = set(os.path.splitext(file)[0] for file in files_in_dataset)\n\n# Find cities that are in weather.csv but not in the dataset folder\ncities_not_scraped = unique_cities_weather[~unique_cities_weather['City'].isin(unique_cities_dataset)]\n\n# Reset index to have a proper index in the final DataFrame\ncities_not_scraped.reset_index(drop=True, inplace=True)\n\n# Save the DataFrame to CSV\noutput_csv_path = '/kaggle/working/cities_not_scraped.csv'\ncities_not_scraped.to_csv(output_csv_path, index=True)\n\nprint(f\"CSV file containing cities not scraped has been saved to: {output_csv_path}\")\n\n# Display the DataFrame\ncities_not_scraped","metadata":{"execution":{"iopub.status.busy":"2024-04-11T17:56:35.145861Z","iopub.execute_input":"2024-04-11T17:56:35.146286Z","iopub.status.idle":"2024-04-11T17:56:35.209580Z","shell.execute_reply.started":"2024-04-11T17:56:35.146252Z","shell.execute_reply":"2024-04-11T17:56:35.208459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cell 5: Find cities not scraped\n\n# Features of the DataFrame\ndf_features = cities_not_scraped.columns.tolist()\n\n# Information about the DataFrame\ndf_info = cities_not_scraped.info()\n\n# Shape of the DataFrame\ndf_shape = cities_not_scraped.shape\n\n# Display all details\ndf_features, df_info, df_shape\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T17:56:37.256948Z","iopub.execute_input":"2024-04-11T17:56:37.257374Z","iopub.status.idle":"2024-04-11T17:56:37.274824Z","shell.execute_reply.started":"2024-04-11T17:56:37.257340Z","shell.execute_reply":"2024-04-11T17:56:37.273527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Cell 7: Plots\n- **Correlation Heatmap with adjusted font size and color palette**:\n- **Histogram of Relative Humidity**:\n- **Scatter Plot of Temperature vs. Dew Point**:\n- **Wind Rose Plot (Assuming you have wind direct# Box Plot of Cloud Cover**:\n- **Box Plot of Cloud Cover**:\n- **Bar Plot of Precipitation Types**:\n- **Line Plot of Wind Speed**:","metadata":{}},{"cell_type":"code","source":"# !pip install matplotlib\n# !pip install seaborn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load the dataset\nfile_path = '/kaggle/working/Dataset/Delhi.csv'\ndata = pd.read_csv(file_path)\n\n# Convert 'date' column to datetime format\ndata['date'] = pd.to_datetime(data['date'])\n\n# Time Series Plot of Temperature\nplt.figure(figsize=(12, 6))\nplt.plot(data['date'], data['temperature_2m'], color='blue')\nplt.title('Temperature Time Series')\nplt.xlabel('Date')\nplt.ylabel('Temperature (°C)')\nplt.grid(True)\nplt.show()\n\n# Correlation Heatmap with adjusted font size and color palette\nplt.figure(figsize=(10, 8))\nsns.heatmap(data.corr(), annot=True, fmt='.2f', cmap='viridis', annot_kws={'size': 10})\nplt.title('Correlation Heatmap')\nplt.show()\n\n# Histogram of Relative Humidity\nplt.figure(figsize=(8, 6))\nplt.hist(data['relative_humidity_2m'], bins=30, color='green', edgecolor='black')\nplt.title('Histogram of Relative Humidity')\nplt.xlabel('Relative Humidity (%)')\nplt.ylabel('Frequency')\nplt.grid(axis='y', alpha=0.75)\nplt.show()\n\n# Scatter Plot of Temperature vs. Dew Point\nplt.figure(figsize=(8, 6))\nplt.scatter(data['temperature_2m'], data['dew_point_2m'], color='orange', alpha=0.5)\nplt.title('Temperature vs. Dew Point')\nplt.xlabel('Temperature (°C)')\nplt.ylabel('Dew Point (°C)')\nplt.grid(True)\nplt.show()\n\n# Wind Rose Plot (Assuming you have wind direction data)\nplt.figure(figsize=(10, 8))\nsns.histplot(data['wind_direction_10m'], bins=36, stat='density', linewidth=0)\nplt.title('Wind Rose Plot')\nplt.xlabel('Wind Direction (degrees)')\nplt.ylabel('Density')\nplt.show()\n\n# Box Plot of Cloud Cover\nplt.figure(figsize=(8, 6))\nsns.boxplot(x=data['cloud_cover'], color='skyblue')\nplt.title('Box Plot of Cloud Cover')\nplt.xlabel('Cloud Cover (%)')\nplt.show()\n\n# Bar Plot of Precipitation Types\nprecipitation_types = ['rain', 'snowfall']\nprecipitation_data = data[precipitation_types].sum()\nplt.figure(figsize=(8, 6))\nplt.bar(precipitation_types, precipitation_data, color=['blue', 'cyan'])\nplt.title('Bar Plot of Precipitation Types')\nplt.xlabel('Precipitation Type')\nplt.ylabel('Total Amount')\nplt.show()\n\n# Line Plot of Wind Speed\nplt.figure(figsize=(12, 6))\nplt.plot(data['date'], data['wind_speed_10m'], color='green')\nplt.title('Wind Speed Time Series')\nplt.xlabel('Date')\nplt.ylabel('Wind Speed (km/h)')\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T18:07:12.187143Z","iopub.execute_input":"2024-04-11T18:07:12.188405Z","iopub.status.idle":"2024-04-11T18:07:22.752227Z","shell.execute_reply.started":"2024-04-11T18:07:12.188367Z","shell.execute_reply":"2024-04-11T18:07:22.751070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>    Violin Plot of Temperature Distribution by Month:</h2>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.violinplot(x=data['date'].dt.month, y=data['temperature_2m'], palette='coolwarm')\nplt.title('Temperature Distribution by Month')\nplt.xlabel('Month')\nplt.ylabel('Temperature (°C)')\nplt.grid(axis='y', alpha=0.75)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T18:00:18.828204Z","iopub.execute_input":"2024-04-11T18:00:18.828902Z","iopub.status.idle":"2024-04-11T18:00:20.161719Z","shell.execute_reply.started":"2024-04-11T18:00:18.828863Z","shell.execute_reply":"2024-04-11T18:00:20.160430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>    Line Plot of Wind Speed and Wind Gusts:</h2>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(data['date'], data['wind_speed_10m'], label='Wind Speed', color='green')\nplt.plot(data['date'], data['wind_gusts_10m'], label='Wind Gusts', color='blue')\nplt.title('Wind Speed and Wind Gusts Time Series')\nplt.xlabel('Date')\nplt.ylabel('Speed (km/h)')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T18:00:39.182906Z","iopub.execute_input":"2024-04-11T18:00:39.183329Z","iopub.status.idle":"2024-04-11T18:00:45.059388Z","shell.execute_reply.started":"2024-04-11T18:00:39.183297Z","shell.execute_reply":"2024-04-11T18:00:45.058298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>    Stacked Area Plot of Precipitation:</h2>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(data['date'], data['rain'], label='Rain', color='blue')\nplt.plot(data['date'], data['snowfall'], label='Snowfall', color='cyan')\nplt.fill_between(data['date'], data['rain'], alpha=0.3, color='blue')\nplt.fill_between(data['date'], data['snowfall'], alpha=0.3, color='cyan')\nplt.title('Total Precipitation (Rain and Snowfall)')\nplt.xlabel('Date')\nplt.ylabel('Amount')\nplt.legend()\nplt.ylim(0, 35)  # Set the y-axis limit to 0-15\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T18:05:45.347827Z","iopub.execute_input":"2024-04-11T18:05:45.348248Z","iopub.status.idle":"2024-04-11T18:05:55.728560Z","shell.execute_reply.started":"2024-04-11T18:05:45.348219Z","shell.execute_reply":"2024-04-11T18:05:55.727360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>    Box Plot of Apparent Temperature by Season:</h2>","metadata":{}},{"cell_type":"code","source":"data['season'] = (data['date'].dt.month%12 + 3)//3\ndata['season'] = data['season'].map({1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'})\nplt.figure(figsize=(10, 6))\nsns.boxplot(x=data['season'], y=data['apparent_temperature'], palette='coolwarm')\nplt.title('Apparent Temperature by Season')\nplt.xlabel('Season')\nplt.ylabel('Apparent Temperature (°C)')\nplt.grid(axis='y', alpha=0.75)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T18:02:01.979548Z","iopub.execute_input":"2024-04-11T18:02:01.979985Z","iopub.status.idle":"2024-04-11T18:02:02.355643Z","shell.execute_reply.started":"2024-04-11T18:02:01.979952Z","shell.execute_reply":"2024-04-11T18:02:02.354596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace infinite values with NaN\ndata.replace([float('inf'), float('-inf')], pd.NA, inplace=True)\n\n# Scatter Plot Matrix\nsns.pairplot(data[['temperature_2m', 'relative_humidity_2m', 'precipitation', 'wind_speed_10m']])\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T18:02:49.940686Z","iopub.execute_input":"2024-04-11T18:02:49.941763Z","iopub.status.idle":"2024-04-11T18:02:58.988320Z","shell.execute_reply.started":"2024-04-11T18:02:49.941727Z","shell.execute_reply":"2024-04-11T18:02:58.987067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2></h2>","metadata":{}},{"cell_type":"markdown","source":"<h2></h2>","metadata":{}}]}